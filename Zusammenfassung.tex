\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{fourier}
\usepackage{float}              
\usepackage{caption}  
\usepackage{adjustbox}
\usepackage{wrapfig}
\usepackage[hidelinks]{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\captionsetup[figure]{name=Abb.}

\lstset{
  language=C,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue}\bfseries,
  commentstyle=\color{green!60!black}\itshape,
  stringstyle=\color{red},
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  showstringspaces=false,
  frame=single,
  breaklines=true
}

\newcommand{\greencheck}{\textcolor{green}{\scalebox{1.5}{\checkmark}}}
\newcommand{\redmark}{\textcolor{red}{\scalebox{2}{$\times$}}}

\begin{document}

\tableofcontents

\newpage

\section{Einführung}

\subsection{Was ist ein Betriebssystem?}

\begin{figure}[H]
\begin{minipage}[t]{0.45\textwidth}
\begin{itemize}
\item Hardware-Ressourcen verwaltet (CPU, Speicher, Festplatte …)
\item Abstraktionen für Anwendungen bereitgestellt \\
$\rightarrow$ Anwendungen müssen Hardware nicht direkt ansprechen
\end{itemize}

\subsubsection*{Hauptaufgaben}
\begin{enumerate}
\item Abstraktion
\begin{itemize}
\item Einheitliches Interface für versch. Hardware
\item Ziel: Wiederverwendung, höhere Abstraktion, einfache Nutzung
\item Herausforderung: Wie viel Hardware soll sichtbar bleiben?
\end{itemize}
\item Ressourcenverwaltung
\begin{itemize}
\item Entscheidet über Nutzung von CPU, RAM, etc.
\item Ziele: Schutz, Effizienz, Fairness
\item Herausforderung: Richtige Mechanismen \& Policies
\end{itemize}
\end{enumerate}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\textwidth}
\centering
\vspace{20mm}
\adjustbox{valign=c}{\includegraphics[scale=0.7]{pictures/virtualisierung/whatos.png}}
\caption{Grober Aufbau}
\end{minipage}
\end{figure}

\subsection{Zentrale Bausteine Betriebssysteme}

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{pictures/virtualisierung/bausteineos.png}
\caption{Bausteine OS}
\end{figure}

\section{Virtualisierung}

\subsection{Prozesse}

\subsubsection{Grundlagen}

\begin{itemize}
\item Prozess: laufende Instanz eines Programms mit eigenem Zustand (Register, Speicher, offene Dateien)
\item Programm: Nur statischer Code \& Daten; ein Prozess ist die dynamische Ausführung davon
\item Programm kann mehrere Prozesse gleichzeitig haben
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{pictures/virtualisierung/erzeugungprozess.png}
\caption{Erzeugung eines Prozesses}
\end{figure}

\subsubsection{Prozess vs. Thread}

\begin{itemize}
\item Thread: Leichtgewichtiger Prozess, teilt sich den Adressraum mit anderen Threads im selben Prozess
\item Prozesse voneinander isoliert, Threads nicht
\end{itemize}

\subsubsection{Virtualisierung CPU}

\begin{itemize}
\item Ziel: Jeder Prozess glaubt, CPU gehöre nur ihm
\item Zeitliche Aufteilung (Time-Sharing) bei Einprozessor-Systemen
\item Direkte Ausführung erlaubt hohe Leistung, aber:
\begin{itemize}
\item Prozesse dürfen nicht direkt privilegierte Operationen ausführen
\item OS muss Prozesse unterbrechen können (z. B. bei Endlosschleifen oder I/O-Wartezeiten)
\end{itemize}
\end{itemize}

\subsubsection{Privilegien \& System Calls}

\begin{itemize}
\item 2 Betriebsmodi:
\begin{itemize}
\item User Mode: Eingeschränkter Zugriff
\item Kernel Mode: Voller Zugriff
\end{itemize}
\item System Calls: definierte Schnittstellen, um vom User-Modus in den Kernel-Modus zu wechseln (z. B. read(), write())
\item CPU führt bei  System Call Moduswechsel durch \& ruft einen System-Call-Handler im Kernel auf
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.75]{pictures/virtualisierung/syscallbsp.png}
\caption{Bsp. SysCall}
\end{figure}

\subsubsection{Multitasking \& Scheduling}

\begin{itemize}
\item Mechanismus: Context-Switch (Wechsel zwischen Prozessen)
\item Policy: Entscheidung, welcher Prozess wann läuft
\item 2 Varianten:
\begin{enumerate}
\item Kooperatives Multitasking: Prozess gibt CPU freiwillig ab (yield())
\begin{itemize}
\item Nachteil: Ein Prozess kann System blockieren
\end{itemize}
\item Präemptives Multitasking: OS erzwingt regelmäßig Kontrolle durch Timer-Interrupts\\
$\rightarrow$ Standard in modernen Systemen
\end{enumerate}
\end{itemize}

\subsubsection{Prozesskontext \& PCB}

\begin{itemize}
\item Beim Wechsel werden Register, Stackpointer usw. im Process Control Block (PCB) gespeichert
\item PCB enthält u. a.:
\begin{itemize}
\item Prozesszustand (running, ready, blocked)
\item Registerinhalte
\item PID, Eltern-/Kindbeziehungen
\item offene Dateien, Berechtigungen, Priorität
\end{itemize}
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{pictures/virtualisierung/gespeicherteInfoPCB.png}
\caption{gespeicherte Infos in PCB}
\end{figure}

\subsubsection{Prozesszustände}

\begin{figure}[H]
\begin{minipage}[t]{0.45\textwidth}
\begin{itemize}
\item Running: Prozess läuft auf CPU
\item Ready: wartet auf CPU
\item Blocked: Wartet auf Ereignis (I/O, Synchronisation)
\item OS verwaltet Ready-Queues \& Event-Queues
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{0.45\textwidth}
\centering
\vspace{-5mm}
\adjustbox{valign=c}{\includegraphics[scale=0.35]{pictures/virtualisierung/pzustand.png}}
\caption{Prozesszustände}
\end{minipage}
\end{figure}

\subsubsection{Prozesserzeugung}

\textbf{2 Hauptwege:}

\begin{enumerate}
\item Leerer neuer Prozess (z.B. \texttt{posix\_spawn(})/\texttt{CreateProcess()}):
\begin{itemize}
\item OS lädt Code, erstellt Stack, initialisiert PCB
\end{itemize}
\item Klonen bestehender Prozesse (Unix: \texttt{fork()} $+$ \texttt{exec()}):
\begin{itemize}
\item \texttt{fork()} $\rightarrow$ Duplikat des aktuellen Prozesses
\item \texttt{exec()} $\rightarrow$ ersetzt Prozessspeicher durch neues Programm
\item Klassisches Unix-Modell (Shells funktionieren so)
\end{itemize}
\end{enumerate}

\subsubsection{Prozessbeendigung}

\begin{itemize}
\item exit(status): Prozess endet mit Rückgabewert
\item Elternprozess ruft wait() auf, um Kindstatus abzuholen
\item Kind bleibt bis dahin als Zombie (defunct) in der Prozesstabelle
\end{itemize}

\subsection{Scheduling}

\subsubsection{Grundidee Schedulings}

\begin{itemize}
\item \textbf{Ziel:} faire, effiziente \& reaktionsschnelle Zuteilung der CPU and Prozesse 
\item \textbf{Scheduler:} entscheidet welcher Prozess als Nächstes läuft 
\item \textbf{Dispatch:} führt tatsächlichen Kontextwechsel (context switch) aus 
\item \textbf{Workload:} Menge an Jobs mit Ankunftszeit ($T_{\text{arrival}}$) \& Laufzeit ($T_{\text{run}}$)
\item \textbf{Metriken:}
\begin{itemize}
\item Durchlaufzeit (Turnaround Time): $T_{\text{turnaround}}= T_{\text{completion}} - T_{\text{arrival}}$
\item Reaktionszeit (Response Time) : $T_{\text{response}} = T_{\text{firstrun}} - T_{\text{arrival}}$
\item Wartezeit \& Overhead minimieren
\item Durchsatz, Ressourcenauslastung \& Fairness maximieren
\end{itemize}
\end{itemize}

\subsubsection{Wichtige Schedulingstrategien}

\begin{enumerate}
\item \textbf{FIFO/FCFS (First Come, First Serve)}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item nicht präemptiv, läuft bis Ende
\item erst A, dann B \& zum Schluss C
\item einfach, aber Konvoi-Effekt $\rightarrow$ 1. langer Job blockiert weitere kurze
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\vspace{-15mm}
\adjustbox{valign=c}{\includegraphics[scale=.35]{pictures/virtualisierung/fifosche.png}}
\caption{$\Delta T_{\text{turnaround}} =(10s+20s+30s)/3 = 20s$}
\end{minipage}
\end{figure}
\item \textbf{SJF (Shortest Job First)}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item nicht präemptiv, wählt kürzesten Job
\item optimal für minimale durchschnittliche Durchlaufzeit (bekannte Laufzeiten)
\item nicht geeignet, wenn Ankunftszeiten unterschiedlich oder Laufzeiten unbekannt
\item kurze Jobs vorziehen verbessert Durchlaufzeit
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\vspace{-7mm}
\adjustbox{valign=c}{\includegraphics[scale=.35]{pictures/virtualisierung/sjfsche.png}}
\caption{$\Delta T_{\text{turnaround}} = (80s+10s+20s)/3 = 36,7s$}
\end{minipage}
\end{figure}
\item \textbf{STCF (Shortest Time to Completion First)}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item präemptive Variante von SJF
\item wählt Job mit kürzester verbleibenden Zeit
\item bessere Reaktionszeit \& geringe mittlere Durchlaufzeit
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\vspace{-15mm}
\adjustbox{valign=c}{\includegraphics[scale=.35]{pictures/virtualisierung/stcfsche.png}}
\caption{$\Delta T_{\text{turnaround}} =(80s+(20s-10s)+(30s-10s))/3 = 36,7s$}
\end{minipage}
\end{figure}
\newpage
\item \textbf{RR (Round Robin)}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item präemptiv mit Zeitquanten(/-scheiben)
\item allen Prozessen gegenüber fair, gut für interaktive Systeme
\item schlechtere Durchlaufzeiten, aber gute Reaktionszeiten
\item Zeitscheibenlänge zu kurz $\rightarrow$ viel Overhead, zu lang $\rightarrow$ schlechte Reaktionszeit
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\vspace{-5mm}
\adjustbox{valign=c}{\includegraphics[scale=.4]{pictures/virtualisierung/fifovsrr.png}}
\caption{FIFO vs RR: \\ $T_{\text{reaction}}= (0+5+10)/3=5$ ~ ~ ~ ~ ~ ~ ~ ~ $T_{\text{reaction}}=(0+1+2)/3=1$}
\end{minipage}
\end{figure}
\end{enumerate}

\subsubsection{Erweiterungen: Realistische Szenarien}

\textbf{I/O-Einfluss}
\begin{itemize}
\item Prozesse wechseln zw. CPU- \& I/O-Phasen
\item CPU-bound vs I/O-bound Prozesse $\rightarrow$ Scheduling muss reagieren
\end{itemize}

\begin{figure}[H]
\begin{minipage}[t]{.5\textwidth}
\centering
\includegraphics[scale=.5]{pictures/virtualisierung/oio.png}
\caption{keine Berücksichtigung von I/O}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\includegraphics[scale=.5]{pictures/virtualisierung/mio.png}
\caption{mit Berücksichtigung von I/O}
\end{minipage}
\end{figure}

\noindent
\textbf{MLFQ (Multi-Level Feedback Queue)}
\begin{itemize}
\item mehrere Priostufen mit Round Robin pro Ebene:
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{enumerate}
\item priority(A) > priority(B), A ausführen
\item priority(A) == priority(B), A \& B nach RR ausführen
\item Start von Prozess mit höchster Prio
\item nutzt Job gesamte Zeitscheibe dann runterstufen
\end{enumerate}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{-10mm}
\adjustbox{valign=c}{\includegraphics[scale=.5]{pictures/virtualisierung/prio.png}}
\caption{Prio nach Round Robin}
\end{minipage}
\end{figure}
\item interaktive Prozesse (I/O-bound) in höheren Queues $\rightarrow$ bessere Reaktionszeit
\item herabstufen von CPU-bound Prozessen
\item Probleme: Starvation \& Systemausnutzung $\rightarrow$ Lösung durch dynamische Anpassung
\end{itemize}

\begin{figure}[H]
\begin{minipage}[t]{.5\textwidth}
\centering
\includegraphics[scale=.4]{pictures/virtualisierung/cpubound.png}
\caption{CPU-bound $\rightarrow$ langlaufender Job}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\includegraphics[scale=.4]{pictures/virtualisierung/iobound.png}
\caption{I/O-bound $\rightarrow$ interaktiver Prozess}
\end{minipage}
\end{figure}

\subsubsection{Modernes Scheduling: CFS (Complety Fair Scheduler, Linux ab 2007)}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item Ziel: Jeder Prozess erhält fairen Anteil der CPU
\item Virtuelle Laufzeit (vruntime): misst tatsächliche CPU-Nutzung
\item Prozesse in Red-Black-Tree sortiert \\ $\rightarrow$ geringste vruntime zuerst
\item Zeitscheiben abhängig von: \\
\[\text{time\_slice} = \frac{\text{sched\_latency}}{\text{\#processes}}\]
mit Mindestwert $\text{min\_granularity}$
\item Prios (nice-Wert) beeinflussen Gewicht
\begin{itemize}
\item nice von -20 (hoch) bis +19 (niedrig)
\item Laufzeit wächst langsamer für hohe Prioritäten
\end{itemize}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\vspace{15mm}
\adjustbox{valign=c}{\includegraphics[scale=.5]{pictures/virtualisierung/vrun.png}}
\caption{Ready Queue in einem Red-Black-Tree}
\end{minipage}
\end{figure}

Prozess k mit Gewicht:
\[\text{time\_slice}_k = \frac{\text{weight}_k}{\sum_{i=0}^{n-1}\text{weight}_i} \cdot \text{sched\_latency}\]
Aktualisierung virtueller Laufzeit:
\[\Delta \text{vruntime}_k = \frac{\text{weight}_0}{\text{weight}_k} \cdot \text{vruntime}_k\]

\begin{figure}[H]
\begin{minipage}[t]{.5\textwidth}
\centering
\includegraphics[scale=.3]{pictures/virtualisierung/cfs.png}
\caption{Bespiel von CFS}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\centering
\includegraphics[scale=.3]{pictures/virtualisierung/cfsprio.png}
\caption{Bespiel von CFS mit Prio}
\end{minipage}
\end{figure}

\subsection{Speichervirtualisierung}

\subsubsection{Grundidee der Virtualisierung}

\begin{itemize}
\item Ziel: Prozesse sollen eigene, isolierte Adressräume haben
\item Mechanismen:
\begin{itemize}
\item virtuelle CPU: Context Switch, Scheduling
\item virtueller RAM: Adressübersetzung, Paging, Swapping
\end{itemize}
\item Policies: Scheduling (CPU), Seitenersetzung (RAM)
\end{itemize}

\subsubsection{Speicherorganisation in Prozessen}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{Addressraum}
\begin{itemize}
\item Jeder Prozess hat eine Reihe von Adressen, die auf
Bytes abgebildet werden
\item statisch: Code, globale Variablen
\item dynamisch: Stack (LIFO), Heap (dynamische Alloc)
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{-15mm}
\adjustbox{valign=c}{\includegraphics[scale=.4]{pictures/virtualisierung/adraum.png}}
\caption{Addressraum}
\end{minipage}
\end{figure}

\noindent
\textbf{Stack}
\begin{itemize}
\item verwaltet lokale Variablen \& Funktionsaufrufe (Stack Frames)
\item Rekursion erzeugt neue Frames
\item Alloc/Dealloc sehr effizient (nur Stackpointer-Bewegung)
\end{itemize}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{Heap}
\begin{itemize}
\item flexible Speicherverwaltung mit \texttt{malloc()} \& \texttt{free()}
\item Probleme: Fragmentierung
\begin{itemize}
\item intern: Block größer als benötigt
\item extern: freie Blöcke zu klein verteilt
\end{itemize}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{5mm}
\adjustbox{valign=c}{\includegraphics[scale=.4]{pictures/virtualisierung/haf.png}}
\caption{Heap mit \texttt{free} \& \texttt{alloc}}
\end{minipage}
\end{figure}

\subsubsection{Speicherverwaltungsstrategien}

\textbf{Free List}
\begin{itemize}
\item freie Blöcke in einer Liste gespeichert
\item First Fit: Beginnend vom Kopf der Liste, finde den ersten genügend großen Block \& teile ihn auf
\item Best Fit: Finde den kleinsten, gerade noch passenden Block für die Alloc
\item Worst Fit: Wenn kein passender Block in der Liste existiert, finde den größten Block \& teile ihn auf (um
kleine Restblöcke zu verhindern)
\item Next Fit: Wie First Fit, aber beginne jeweils hinter dem zuletzt aufgeteilten Block
\item Coalescing = Nachbarblöcke zsmführen
\end{itemize}

\noindent
\textbf{Buddy Allocator}
\begin{itemize}
\item Speicher in 2er-Potenzen geteilt
\item vereinfacht zsmführen (\glqq Buddy\grqq -Blöcke, XOR)
\item Nachteil: feste Blockgrößen $\rightarrow$ interne Fragmentierung
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=.325]{pictures/virtualisierung/bulloc.png}
\caption{Bsp zum Buddy Allocator}
\end{figure}

\subsubsection{Speicherzugriff}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{Variablen je nach Typ}
\begin{itemize}
\item Code: ausführbarer Speicher
\item Statische Daten: global
\item Stack: lokale Variablen
\item Heap: dynamic allocated data
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.6\textwidth}
\begin{lstlisting}
int x;

int main(int argc, char *argv[]) {
	int y;
	int *z;
	z = malloc(sizeof(int));
}
\end{lstlisting}
\end{minipage}
\end{figure}

\subsubsection{Virtualisierung des Speichers}

Ziel: Mehrere Prozesse gleichzeitig ohne Konflikte

\begin{enumerate}
\item Zeitliche Aufteilung (time sharing)
\begin{itemize}
\item Prozesse nacheinander im RAM, Rest auf Disk
\item extrem langsamer Disk-I/O bei jedem Kontaktwechsel
\begin{figure}[H]
\begin{minipage}[t]{.15\textwidth}
\centering
\includegraphics[scale=.15]{pictures/virtualisierung/time_share_1.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.2\textwidth}
\centering
\includegraphics[scale=.15]{pictures/virtualisierung/time_share_2.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\centering
\includegraphics[scale=.15]{pictures/virtualisierung/time_share_3.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\centering
\includegraphics[scale=.15]{pictures/virtualisierung/time_share_4.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.15\textwidth}
\centering
\includegraphics[scale=.15]{pictures/virtualisierung/time_share_5.png}
\end{minipage}
\caption{Beispiel zum Time-Share-Speicher}
\end{figure}
\end{itemize}
\item Statische Verschiebung
\begin{itemize}
\item OS schreibt Programm beim Laden um (Adressen anpassen)
\item kein Schutz, keine flexible Umschichtung
\begin{figure}[H]
\centering
\includegraphics[scale=.4]{pictures/virtualisierung/speicherlayout.png}
\caption{Layout im Speicher}
\end{figure}
\end{itemize}
\item Dynamische Verschiebung (Basisregister)
\begin{itemize}
\item Hardware (MMU) addiert bei jedem Zugriff einen Offset (Basisregister)
\item jeder Prozess bekommt eigenes Basisregister $\rightarrow$ Schutz möglich
\item kein Limit $\rightarrow$ Prozess kann in Speicher anderer schreiben
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.25]{pictures/virtualisierung/mmu.png}
\caption{MMU ändert Prozessadresse dynamisch}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.25]{pictures/virtualisierung/basisregister.png}
\caption{Implementierung Basisregister}
\end{minipage}
\end{figure}
\end{itemize}
\item Base + Bounds
\begin{itemize}
\item zusätzliches Bounds-Register begrenzt Adressraumgröße
\item Schutz bei Überschreitung $\rightarrow$ Interrupt
\item schnell, einfach, geschützt
\item jeder Prozess braucht zusammenhängenden Speicher
\begin{figure}[H]
\centering
\includegraphics[scale=.4]{pictures/virtualisierung/base+bounds.png}
\caption{Base+Bounds Implementierung}
\end{figure}
\end{itemize}
\item Segmentierung
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item Adressraum in logische Segmente (Code, Stack, Heap) geteilt
\item jedes Segment hat eigenes Base+Bounds \& Schutzrechte
\item getrenntes Wachsen, selektives Sharing, Schutz
\item externe Fragmentierung, Speicher evtl. nicht contiguous
\item Berechnen der Adressen:
\begin{itemize}
\item Segmentgröße: $2^{\text{Offset}}$
\item Startadressen der Segmente: $k \cdot 2^n$
\item Endadressen der Segmente: $(k+1) \cdot 2^n - 1$ oder $k \cdot 2^n + (2^n - 1)$
\item Offset = virtuelle Adresse - Startadresse
\item physische Adresse = Base + Offset
\end{itemize}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{12mm}
\includegraphics[scale=.5]{pictures/virtualisierung/segimp.png}
\caption{Segmentierung Implementierung}
\end{minipage}
\noindent
\end{figure}
\end{enumerate}

\subsection{Paging}

\subsubsection{Idee von Paging}

\textbf{Ziel:} Speicher in gleichgroße Blöcke zerlegen, um Fragmentierung zu vermeiden

\begin{itemize}
\item virtuelle Adressräume $\rightarrow$ Pages
\item physischer Speicher $\rightarrow$ Frames
\item jede virtuelle Seite kann in beliebigen physischen Rahmen liegen
\item Vorteile
\begin{enumerate}
\item keine externe Fragmentierung
\item schnelle Allokation \& Freigabe
\item Auslagerung von Teilen des Hauptspeicher in Festspeicher möglich (swapping)
\end{enumerate}
\item Nachteile
\begin{enumerate}
\item interne Fragmentierung, Seite größer als Speicher
\item hohe Kosten durch zusätzlichen Speicherzugriff
\item Platzbedarf für Seitentabellen
\end{enumerate}
\end{itemize}

\subsubsection{Aufbau virtueller Adressen}

\begin{figure}[H]
\begin{minipage}[t]{.33\textwidth}
\centering
\includegraphics[scale=.25]{pictures/virtualisierung/logphy.png}
\caption{Logisch zu Physisch}
\end{minipage}
\hfill
\begin{minipage}[t]{.33\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/adform.png}
\caption{Adressformat}
\end{minipage}
\hfill
\begin{minipage}[t]{.33\textwidth}
\centering
\includegraphics[scale=.25]{pictures/virtualisierung/virtphy.png}
\caption{Virtuell zu Physisch}
\end{minipage}
\end{figure}

\subsubsection{Seitentabellen}

\begin{itemize}
\item Größe einer Seitentabelle = Anzahl Einträge ($2^n$) $\cdot$ Größe eines Eintrags in bytes
\item Seitentabelle im Hauptspeicher
\item Jede Seite hat ein Page Table Entry (PTE)
\begin{itemize}
\item Valid Bit: Seitentabelleneintrag gültig (V)?
\item Present Bit: Seite im Speicher vorhanden (P)?
\item Protection Bits: Seite les- (r), schreib- (w) und/oder ausführnar (x)?
\item Accessed Bits: Kürzlich auf Seite zugegriffen (A)?
\item Dirty Bit: Seite bereits einmal verändert (D)?
\end{itemize}
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=.45]{pictures/virtualisierung/seitentabelle.png}
\caption{Veranschaulichung zur Nutzung von Seitentabellen}
\end{figure}

\subsubsection{Translation Lookaside Buffer (TLB)}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{Cache für Adressübersetzungen in der MMU}
\begin{itemize}
\item bei TLB-Hit: schnelle Übersetzung
\item bei TLB-Miss: PTE muss aus RAM geladen werden
\item TLB-Performance kann durch größere Seiten bei gegebener Anzahl Einträgen verbessert werden
\item Effektivität stark abhängig von Locality
\begin{enumerate}
\item Spatial Locality: benachbarte Adressen (Arrayzugriffe)
\item Temporal Locality: Wiederholte Zugriffe
\end{enumerate}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{5mm}
\includegraphics[scale=.3]{pictures/virtualisierung/worktlb.png}
\caption{Workload-Zugriffsmuster}
\end{minipage}
\end{figure}

\begin{figure}
\begin{minipage}[t]{.45\textwidth}
Beispiele:
\begin{itemize}
\item Arrayzugriff: fast nur TLB-Hits $\rightarrow$ sehr schnell
\item zufälliges Zugriffsmuster ohne Wiederholungen: viele Misses $\rightarrow$ langsam
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
Berechnungen
\begin{itemize}
\item Fehlerrate = \#TLB-Fehler / \#TLB-Zugriffe, 1 - Trefferrate
\item TLB-Zugriffe = Anzahl der Zugriffe auf ...
\item TLB-Fehler = Anzahl Zugriffe auf unterschiedliche Seiten
\end{itemize}
\end{minipage}
\end{figure}

\subsubsection{TLB Ersetzungsstrategien}

\begin{itemize}
\item Least Recently Used (LRU): am längsten ungenutzten TLB Eintrag entfernen (evict)
\item Random: züfälligen Eintrag entfernen
\item Random in bestimmten Fällen besser als LRU
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=.75]{pictures/virtualisierung/bsplru.png}
\caption{Pathologischer Fall LRU - jeder Zugriff ein TLB Miss durch Entfernung der Übersetzung vor Nutzung}
\end{figure}

\subsubsection{Mehrstufige Seitentabellen}

\textbf{Lösung für große Seitentabellen, da Seitentabellen viel Platz benötigen und zusammenhängend gespeichert werden müssen! Es können ungültige Einträge vermieden werden.}

\begin{itemize}
\item Seitentabelle selbst in Seiten aufgeteilt
\item äußere Ebene = Page Directory
\item innere Ebene = Page Table
\item nur tatsächliche Teilstrukturen angelegt
\item weniger Verbrauch \& unterstützt große Adressräume (64-Bit)
\item weitere andere Möglichkeiten: invertierte (physischer Rahmen auf Seiten) oder segmentierte Seitentabellen
\end{itemize}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.17]{pictures/virtualisierung/mehrseit0.png}
\caption{Problem großer Seitentabellen}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.17]{pictures/virtualisierung/mehrseit1.png}
\caption{Idee mehrstufiger Seitentabelle}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.17]{pictures/virtualisierung/mehrseit2.png}
\caption{Beispiel zur mehrstufigen Seitentabelle}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.17]{pictures/virtualisierung/mehrseit3.png}
\caption{Addressformat bei mehr als 2 Stufen}
\end{minipage}
\end{figure}

\subsubsection{Virtueller Speicher \& Swapping}

\textbf{Ziel von OS:} Unterstützung der Prozesse, wenn nicht genug physischer Speicher vorhanden 

\begin{itemize}
\item ungenutzte Seiten auf HDD/SSD ausgelagert
\item PTE zeigt, ob Seite auf Disk
\item Locality innerhalb Prozesse nutzen
\item Zugriff auf ausgelagerte Seite $\rightarrow$ Page Fault
\item Betriebssystem
\begin{enumerate}
\item wählt Opfer-Seite (falls RAM voll)
\item schreibt diese ggf. zurück (Dirty Bit)
\item lädt geforderte Seite in RAM
\item aktualisiert PTE \& TLB
\end{enumerate}
\item PTE = 0 $\rightarrow$ Nirgendwo
\item PTE $\neq$ 0 \& Present = 0 $\rightarrow$ Festplatte (langsam, groß, billig)
\item PTE $\neq$ 0 \& Present $\neq$ 0 $\rightarrow$ Hauptspeicher (klein, schneller, teuer)
\end{itemize}

\noindent

\textbf{Zentrale Beobachtung}

\begin{itemize}
\item Prozesse nutzen nur einen kleinen Teil ihres Adressraums aktiv
\item Virtueller Speicher erzeugt Illusion eines großen Hauptspeichers
\end{itemize}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.35]{pictures/virtualisierung/speicherhierarchie.png}
\caption{Speicherhierarchie}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.3]{pictures/virtualisierung/presentbit.png}
\caption{Present Bit}
\end{minipage}
\end{figure}

\subsection{Virtueller Speicher}

\subsubsection{Wekzeuge zur Analyse}

\begin{itemize}
\item \texttt{pmap -X} zeigt Adressraum eines Prozesses inkl. Berechtigungen, Größe, RSS/PSS usw.
\item \texttt{free}, \texttt{vmstat}, \texttt{perf} helfen beim Überwachen von Speicher \& TLB-Misses
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=.3]{pictures/virtualisierung/pmap.png}
\caption{Beispiel von simple.c}
\end{figure}

\subsubsection{Speicherlayout vs Spatial Locality}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item Row-major Zugriffe $\rightarrow$ gute räumliche Lokatilät
\item Column-first $\rightarrow$ viele TLB-Misses, deutlich schlechter
\item Beispiel mit Matrixmultiplikation:
\begin{itemize}
\item 1000 x 1000 x 1000
\item Row-major: \textasciitilde 10000 TLB-Misses, 2.1s Laufzeit
\item Column-major: > 1.5 Milliarden TLB-Misses, 6s Laufzeit
\end{itemize}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{0mm}
\includegraphics[scale=.3]{pictures/virtualisierung/slayout.png}
\caption{Beispielcode \& Veranschaulichung}
\end{minipage}
\end{figure}

\subsubsection{Mechanismen für virtuellen Speicher}

Ablauf eines Speicherzugriffs:
\begin{enumerate}
\item Hardware prüft TLB
\item bei Miss $\rightarrow$ Hardware/OS durchsucht Seitentabelle
\item bei fehlender Seite: \textbf{Page Fault Trap} $\rightarrow$ OS lädt Seite nach
\item Prozess setzt transparent fort (dank präziser Interrupts)
\end{enumerate}

\subsubsection{Policies für Virtuellen Speicher}

\textbf{Seitenauswahl}
\begin{itemize}
\item \textbf{Demand Paging:} Laden erst bei Bedarf $\rightarrow$ viele Page Faults bei Start
\item \textbf{Prepaging/Prefetching:} Vorhersagebasierte Seitenladung
\item \textbf{Hinting:} User spezifiziert, z.B. mittels \texttt{madvise()}
\end{itemize}
\noindent
\textbf{Seitenersetzung}
\begin{itemize}
\item \textbf{OPT (Optimaler Algo):} ersetzt Seite, die am längsten in der Zukunft nicht verwendet wird
\item \textbf{FIFO:} älteste Seite raus $\rightarrow$ einfach, aber problematisch
\item \textbf{LRU:} Seite, deren letzter Zugriff am längsten her ist
\end{itemize}
\noindent
\textbf{Belady's Anomalie}
\begin{itemize}
\item mehr physischer Speicher kann mehr Page Faults erzeugen bei FIFO
\item z.B. ABCDABEABCDE bei 3 vs 4 Seiten: 9 vs 10 Seitenfehler
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=.4]{pictures/virtualisierung/seitenersetzung.png}
\caption{OPT, FIFO \& LRU im Vergleich bei Seitenersetzung}
\end{figure}

\subsubsection{Problem \& Implentierungen LRU}

\textbf{LRU Probleme}
\begin{itemize}
\item vernachlässigt Häufigkeit der Nutzung
\item große Scans können Cache/Frame flushen
\end{itemize}
\noindent
\textbf{Implementierungsvarianten}
\begin{itemize}
\item Software-Perfect-LRU: genaue Liste $\rightarrow$ teuer bei Zugriffen
\item Hardware-Perfect-LRU: Zeitstempel $\rightarrow$ teuer beim Ersetzen
\item in der Praxis vereinfachte Näherungen: einfach eine alte Seite finden, nicht unbedingt die Älteste
\end{itemize}

\subsubsection{Clock-Algorithmus}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item jede Seite hat ein Reference Bit (Hardware)
\item scannt im Uhrzeigersinn (Software)
\item Reference Bit = 1 $\rightarrow$ löschen \& weiter
\item Reference Bit = 0 $\rightarrow$ Seite wird ersetzt
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\vspace{-5mm}
\includegraphics[scale=.25]{pictures/virtualisierung/clock1.png}
\caption{Beispiel für nachfolgende Schritte des Algos}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock2.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock3.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock4.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock5.png}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock6.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock7.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock8.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock9.png}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock10.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock11.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock12.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock13.png}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock14.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock15.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock16.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[scale=.2]{pictures/virtualisierung/clock17.png}
\end{minipage}
\caption{Veranschaulichung des Clock-Algos von links nach rechts durch jede Zeile}
\end{figure}

\textbf{Erweiterungen des Algos}
\begin{itemize}
\item mehrere Seiten auf einmal ersetzen
\item Software-Zähler für Nutzungswahrscheinlichkeit
\item Dirty-Bit ausnutzen: nicht modifizierte Seiten bevorzugt auslagern
\end{itemize}

\section{Nebenläufigkeit}

\subsection{Threads \& Wechselseitiger Ausschluss}

\subsubsection{Gängige Programmiermodelle}

\begin{itemize}
\item \textbf{Producer/Consumer} \\
Mehrere Producer-Threads erstellen Daten/Arbeit, die von einem Consumer-Thread verarbeitet werden
\item \textbf{Pipeline} \\
Eine Aufgabe wird in eine Reihe von Teilaufgaben aufgeteilt, die jeweils nacheinander von einem anderen Thread bearbeitet werden
\item \textbf{Background Thread} \\
Ein Thread führt nicht-kritische Arbeit im Hintergrund aus (wenn CPU untätig)
\end{itemize}

\subsubsection{Thread vs. Prozess}

\textbf{Prozesse:} eigener Adressraum, eigene Ressourcen \\
\textbf{Threads:} mehrere parallele Ausführungsstränge innerhalb eines Prozesses \\

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{Threads teilen:}
\begin{itemize}
\item Adressraum (PTBR, Code, Heap, globale Variablen)
\item File Descriptors
\item PID (teilweise), UID, GID
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\textbf{Threads haben individuell:}
\begin{itemize}
\item Registersatz (IP: Instruction Pointer, SP: Stack Pointer)
\item eigenen Stack
\item Thread ID (TID)
\end{itemize}
\end{minipage}
\centering
\includegraphics[scale=.5]{pictures/nebenläufigkeit/threadcpu.png}
\caption{Veranschaulichung von Thread in CPUs}
\end{figure}

\subsubsection{Thread-Modelle}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{User Threads} \\
\greencheck portabel \& schnell \\
\greencheck Scheduling Policies von Anwendung selbst angepasst \\
\greencheck niedriger Overhead, da keine System Calls \\
\redmark blockiert ein Thread, ganzer Prozess blockiert \\
\redmark keine Nutzung von MultiCPU-Systemen
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\textbf{Kernel Threads} \\
\greencheck echter Parallelismus \\
\greencheck blockierter Thread blockiert andere nicht \\
\redmark höherer Overhead \\
\redmark OS muss mit steigender Anzahl von Threads skalieren
\end{minipage}
\end{figure}

\textbf{Gängige Operationen (egal ob POSIX (pthreads), Win32, C++, Java, etc.):}
\begin{itemize}
\item \texttt{thread\_create()}
\item \texttt{thread\_exit()}
\item \texttt{thread\_join()}
\end{itemize}

\subsubsection{Nebenläufigkeit \& Race Conditions}

\begin{figure}[H]
\begin{minipage}[t]{.33\textwidth}
\centering
\includegraphics[scale=.25]{pictures/nebenläufigkeit/zeitleiste1.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.33\textwidth}
\centering
\includegraphics[scale=.25]{pictures/nebenläufigkeit/zeitleiste2.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.33\textwidth}
\centering
\includegraphics[scale=.25]{pictures/nebenläufigkeit/zeitleiste3.png}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.35]{pictures/nebenläufigkeit/zeitleiste4.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.35]{pictures/nebenläufigkeit/zeitleiste5.png}
\end{minipage}
\caption{Beispiele Thread Scheduling}
\end{figure}

\textbf{Nichtdeterminismus}
\begin{itemize}
\item Nebenläufigkeit kann zu nicht deterministischen Ergebnissen führen
\item unterschiedliche Ergebniss bei gleichen Eingaben
\item Race Condition: hängt vom Scheduling ab
\item Tests unzuverlässig
\end{itemize}

\noindent
\textbf{Ziel für korrekte Nebenläufigkeit}
\begin{itemize}
\item nur ein Thread gleichzeitig im kritischen Bereich
\item Ziel: wechselseitiger Ausschluss
\end{itemize}

\subsubsection{Synchronisationsmechanismen}

Das OS soll Konstrukte bereitstellen, die Korrektheit garantieren.

\begin{figure}[H]
\begin{minipage}[t]{.5\textwidth}
\textbf{High-Level:}
\begin{itemize}
\item Locks (Mutex)
\item Semaphore
\item Monitore
\item Condition Variables
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\textbf{Low-Level:}
\begin{itemize}
\item Test-and-Set
\item Compare-and-Swap
\item Fetch-and-Add
\item Interrupts deaktivieren (nur uni-cpu-tauglich)
\end{itemize}
\end{minipage}
\end{figure}

\subsubsection{Lock-Implementierungen}

Ziele von Locks sind Korrektheit, also wechselseitiger Ausschluss, Fairness, jeder Thread muss gleich lange warten \& Performance, CPU wird nicht für unnötige Arbeit verwendet.
\\
\\
\noindent
\textbf{3 Operationen:}
\begin{itemize}
\item Allokieren \& Initialisieren
\item Acquire (exklusiver Zugriff auf Lock, Warten wenn Lock nicht verfügbar, Aktives Warten/Blockieren)
\item Release
\end{itemize}

\newpage

\begin{enumerate}
\item \textbf{Locks durch Unterbinden von Interrupts}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item funktioniert nur auf 1 CPU 
\item blockiert gesamtes System 
\item nicht skalierbar
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\vspace{-10mm}
\begin{lstlisting}[language=C]
void acquire() {
	disableInterrupts();
}
void release() {
	enableInterrupts();
}
\end{lstlisting}
\end{minipage}
\end{figure}
\item \textbf{Spinlocks mit Load+Store}
\begin{figure}[H]
\begin{minipage}[t]{.5\textwidth}
\begin{lstlisting}[language=C]
int lock = 0; // shared variable

void acquire(int *lock) {
	while (*lock == 1) /* wait */ ;
	*lock = 1;
}

void release(int *lock) {
*lock = 0;
}
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\vspace{15mm}
\begin{itemize}
\item beide Threads setzen Lock
\item prüfen \& schreiben nicht atomar $\rightarrow$ Race Condition
\end{itemize}
\end{minipage}
\end{figure}
\item \textbf{Test-and-Set (xchg)}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item Hardwareunterstützung für atomare Bausteine für Locks
\item atomic xchg liest \& schreibt Wert atomar
\item Pseudocode C: gibt zurück was vorher stand
\begin{lstlisting}[language=C]
int xchg(int *addr, int newval) {
	int old = *addr;
	*addr = newval;
	return old;
}
\end{lstlisting}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\vspace{-10mm}
\begin{lstlisting}[language=C]
//Echter C-Code mit inline Assembly

static inline int xchg(volatile int *addr, int newval) {
	int result;
	asm volatile("lock; xchgl %0, %1" :
		"+m" (*addr), "=a" (result) :
		"1" (newval) : "cc");
	return result;
}
}
\end{lstlisting}
\end{minipage}
\end{figure}
\item \textbf{Compare-and-Swap (CAS)}
\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item Alternative zu Test-and-Set, erlaubt noch komplexere Mechanismen
\item vergleicht \& schreibt Wert ggf. atomar
\item Echte built-in Funktion für C (nicht nur fpr int):
\begin{lstlisting}[language=C]
int __sync_val_compare_and_swap(int *ptr, int oldval, int newval)
\end{lstlisting}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
Pseudocode in C:
\begin{lstlisting}[language=C]
int cas(int *addr, int expected, int new) {
	int actual = *addr;
	if (actual == expected)
		*addr = new;
	return actual;
}
\end{lstlisting}
Implementierung auf x86 z.B. mit cmpxchg8b Instruktion
\end{minipage}
\end{figure}
\end{enumerate}

\begin{figure}[H]
\centering
\includegraphics[scale=.5]{pictures/nebenläufigkeit/spinlocks.png}
\caption{Scheduler unabhängig von lock/unlock}
\end{figure}

\begin{figure}[H]
\begin{minipage}[t]{.4\textwidth}
\textbf{Spinlock mit Test-and-Set}
\begin{lstlisting}[language=C]
int xchg(int *addr, int newval) {
	int old = *addr;
	*addr = newval;
	return old;
}

int lock = 0;

void acquire(int *lockp) {
	while(xchg(lockp, 1) == 1);
	// spin-wait (do nothing)
}

void release(int *lockp) {
	*lockp = 0;
}
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}[t]{.55\textwidth}
\textbf{Spinlock mit Compare-and-Swap}
\begin{lstlisting}[language=C]
int cas(int *addr, int expected, int new) {
	int actual = *addr;
	if (actual == expected)
		*addr = new;
	return actual;
}

	int lock = 0;
	
void acquire(int *lockp) {
	while(cas(lockp, 0, 1) == 1);
	// spin-wait (do nothing)
}

void release(int *lockp) {
	*lock = 0;
}
\end{lstlisting}
\end{minipage}
\end{figure}

\noindent
\textcolor{red}{\textbf{$\Rightarrow$ ACHTUNG:}} Spinlocks sind nicht fair, da Thread unterschiedlich oft zum Zug kommen

\subsubsection{Ticket Locks (fair!)}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\begin{itemize}
\item jeder Thread zieht Ticketnummer
\item mit Fetch-and-Add
\item Ablauf:
\begin{enumerate}
\item \texttt{myturn = fetch\_and\_add(ticket)}
\item spin until \texttt{turn = myturn}
\item \texttt{unlock()}: \texttt{turn++}
\end{enumerate}
\item garantierte Fairness
\item Compiler Built-in (nicht nur für int):
\begin{lstlisting}[language=C]
int __sync_fetch_and_add(int *ptr, int value)
\end{lstlisting}
\end{itemize}
\end{minipage}
\hfill
\begin{minipage}[t]{.5\textwidth}
\begin{lstlisting}[language=C]
//Implementierung auf x86 mit lock xadd Instruktion

static inline int fetch_and_add(volatile unsigned *addr) {
	unsigned value = 1;
	__asm__ volatile("lock; xaddl %0, %1"
 		: "+r" (value), "+m" (*addr)
		: : "memory"
	);
	return value;
}
\end{lstlisting}
\end{minipage}\\
fetch\_and\_add liest Wert \& erhöht atomar, gibt alten Wert zurück:
\begin{lstlisting}[language=C]
int fetch_and_add(int *ptr) {
	int old = *ptr;
	*ptr = old + 1;
	return old;
}
\end{lstlisting}
\end{figure}

\noindent
\textbf{Implementierung Ticket Lock}
\begin{lstlisting}[language=C]
typedef struct {
	volatile unsigned ticket;
	volatile unsigned turn;
} lock_t;

void init(lock_t *lock) {
	lock->ticket = 0;
	lock->turn = 0;
}

void acquire(lock_t *lock) {
	unsigned myturn = fetch_and_add(&lock->ticket);
	while (lock->turn != myturn); // spin
}

void release(lock_t *lock) {
	fetch_and_add(&lock->turn);
}
\end{lstlisting}

\begin{figure}[H]
\begin{minipage}[t]{.19\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock1.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.19\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock2.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.19\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock3.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.19\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock4.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.19\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock5.png}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock6.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock7.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock8.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock9.png}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock10.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock11.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock12.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.24\textwidth}
\centering
\includegraphics[width=\linewidth]{pictures/nebenläufigkeit/ticketlock13.png}
\end{minipage}
\caption{Veranschaulichung des Ablaufs von Ticket Locks }
\end{figure}

\subsubsection{Spinlock Performance}

\begin{figure}[H]
\begin{minipage}[t]{.45\textwidth}
\textbf{Schnell wenn...}
\begin{itemize}
\item viele CPUS vorhanden (im Verhältnis zu Threads)
\item Locks kurz gehalten
\item Vorteil: kein Context-Switch
\end{itemize}
\noindent
\textbf{Langsam wenn...}
\begin{itemize}
\item Uniprozessorsystem
\item lange Locks
\item Nachteil: Spinning ist Ressourcenverschwendung
\end{itemize}
\noindent
\textbf{Vergeudetete Zeit:}
\begin{itemize}
\item ohne yield: O(threads $\cdot$ time\_slice)
\item mit yield: O(threads $\cdot$ context\_switch)
\end{itemize}
$\rightarrow$ Sogar mit yield sind Spinlocks bei hoher Thread-Last langsam \\
$\rightarrow$ Besser: blockierend Locks
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\vspace{5mm}
\begin{lstlisting}[language=C]
typedef struct {
	int ticket;
	int turn;
} lock_t;

void lock_init(lock_t *lock) {
	lock->ticket = 0;
	lock->turn = 0;
}

void acquire(lock_t *lock) {
	int myturn = fetch_and_add(&lock->ticket);
	while (lock->turn != myturn)
	yield();
}

void release (lock_t *lock) {
	fetch_and_add(&lock->turn);
}
\end{lstlisting}
\end{minipage}
\\[1em]
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.27]{pictures/nebenläufigkeit/spinlockperf1.png}
\end{minipage}
\hfill
\begin{minipage}[t]{.45\textwidth}
\centering
\includegraphics[scale=.2]{pictures/nebenläufigkeit/spinlockperf2.png}
\end{minipage}
\caption{Performance bei Spinning \& Yield}
\end{figure}

\end{document}